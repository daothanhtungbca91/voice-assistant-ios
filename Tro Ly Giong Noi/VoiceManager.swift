//
//  VoiceManager.swift
//  Demo GPT API
//
//  Created by Tung Dao Thanh on 15/8/25.
//

import UIKit
import Foundation
import Speech
import AVFoundation

extension Notification.Name {
    static let micStateChanged = Notification.Name("micStateChanged")
}

class VoiceManager: NSObject, AVSpeechSynthesizerDelegate {
        
    static let shared = VoiceManager()

    private let audioEngine = AVAudioEngine()
    private var request: SFSpeechAudioBufferRecognitionRequest?
    private var recognizer: SFSpeechRecognizer?
    private var task: SFSpeechRecognitionTask?

    private var synthesizer = AVSpeechSynthesizer()
    var isListening = false
    
    // Timer: 10s ch·ªù b·∫Øt ƒë·∫ßu n√≥i, 3s im l·∫∑ng sau khi b·∫Øt ƒë·∫ßu
    private var startSpeakingTimer: Timer?
    private var silenceTimer: Timer?
    
    private var isStoppedByTimeout = false
    
    // Gi·ªØ l·∫°i transcript cu·ªëi c√πng
    private var lastTranscript: String?
    
    private let loi_mo_dau:String = "Xin ch√†o, t√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n"
    
    private let loi_tiep_tuc:String = "M·ªùi b·∫°n n√≥i"
        
    // C√°c l·ªánh d·ª´ng app
    private let stopCommands: [String] = [
        "d·ª´ng l·∫°i",
        "tho√°t ·ª©ng d·ª•ng",
        "d·ª´ng ·ª©ng d·ª•ng",
        "d·ª´ng tr·ª£ l√Ω"
    ]
    
    private let cameraCommands: [String] = [
        "m√¥ t·∫£ xung quanh t√¥i",
        "m√¥ t·∫£ xung quanh",
        "t·∫£ xung quanh",
        "xung quanh",
        "xung quanh t√¥i",
        "t·∫£ xung quanh t√¥i",
        "c√≥ g√¨ xung quanh",
    ]
    
    private let timeCommands: [String] = [
        "b√¢y gi·ªù l√† m·∫•y gi·ªù",
        "gi·ªù l√† m·∫•y gi·ªù",
        "l√† m·∫•y gi·ªù",
        "m·∫•y gi·ªù r·ªìi",
    ]
    
    private let dateCommands: [String] = [
        "h√¥m nay l√† ng√†y n√†o",
        "h√¥m nay l√† ng√†y m·∫•y",
        "h√¥m nay l√† th·ª© m·∫•y",
        "nay l√† ng√†y n√†o",
    ]
    
    private let lunaCommands: [String] = [
        "l·ªãch √¢m h√¥m nay l√† ng√†y n√†o",
        "√¢m l·ªãch h√¥m nay l√† ng√†y n√†o",
        "l·ªãch √¢m l√† ng√†y n√†o",
        "√¢m l·ªãch l√† ng√†y n√†o",
        "√¢m l·ªãch l√† ng√†y m·∫•y",
        "l·ªãch √¢m l√† ng√†y m·∫•y",
        "√¢m l·ªãch",
    ]
    
//    private let callCommands: [String] = [
//        "g·ªçi ƒëi·ªán tho·∫°i",
//        "ƒëi·ªán tho·∫°i",
//    ]
    
    private let guideCommands: [String] = [
        "h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng",
        "ƒë·ªçc h∆∞·ªõng d·∫´n",
        "h∆∞·ªõng d·∫´n",
        "d·∫´n s·ª≠ d·ª•ng",
        "s·ª≠ d·ª•ng",
        "s·ª≠ d·ª•ng nh∆∞ n√†o",
    ]
    
    private let speedIncreaseCommands: [String] = [
        "tƒÉng t·ªëc ƒë·ªô ƒë·ªçc",
        "tƒÉng t·ªëc ƒë·ªô",
    ]
    
    private let speedDecraseCommands: [String] = [
        "gi·∫£m t·ªëc ƒë·ªô ƒë·ªçc",
        "gi·∫£m t·ªëc ƒë·ªô",
    ]

    
    private var timeoutCount = 0
    private var maxTimeoutCount = StringResources.default_time_out_count
    
    var isManuallyStopped = false

    // Completion cho announce
    private var announceCompletion: (() -> Void)?

    // L∆∞u l·ªãch s·ª≠ h·ªôi tho·∫°i
    private var conversationHistory: [[String: String]] = []

    // Reset to√†n b·ªô h·ªôi tho·∫°i
    func resetConversation() {
        conversationHistory.removeAll()
        print("üßπ ƒê√£ reset l·ªãch s·ª≠ h·ªôi tho·∫°i")
    }

    override init() {
        super.init()
        synthesizer.delegate = self
        recognizer = SFSpeechRecognizer(locale: Locale(identifier: "vi-VN"))
    }

    func resetSynthesizer() {
        synthesizer.stopSpeaking(at: .immediate)
        synthesizer = AVSpeechSynthesizer()
        synthesizer.delegate = self
    }
    
    func startListening(startApp: Bool = true) {
        print("startListening is called")
                
        UIApplication.shared.isIdleTimerDisabled = true

        if isListening {
            stopAll() // reset h·∫≥n tr∆∞·ªõc
        }

        isListening = true
        isStoppedByTimeout = false
        isManuallyStopped = false
        lastTranscript = nil

        // Hu·ª∑ timer c≈© (n·∫øu c√≤n)
        startSpeakingTimer?.invalidate()
        startSpeakingTimer = nil
        silenceTimer?.invalidate()
        silenceTimer = nil

        NotificationCenter.default.post(
            name: .micStateChanged,
            object: nil,
            userInfo: ["isListening": true]
        )

        SFSpeechRecognizer.requestAuthorization { status in
            guard status == .authorized else {
                self.announce("Kh√¥ng c√≥ quy·ªÅn nh·∫≠n d·∫°ng gi·ªçng n√≥i")
                self.isListening = false
                return
            }
            // üîä ƒê·ªçc l·ªùi m·ªùi tr∆∞·ªõc
            if(startApp){
                self.announce(self.loi_mo_dau)
            }
            else{
                self.announce(self.loi_tiep_tuc)
            }
        }
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        // G·ªçi completion n·∫øu c√≥
        announceCompletion?()
        announceCompletion = nil

        // ‚úÖ v·∫´n gi·ªØ logic c≈©: n·∫øu ƒë·ªçc xong l·ªùi m·ªùi ‚Üí startRecording()
        if utterance.speechString == loi_mo_dau || utterance.speechString == loi_tiep_tuc {
            DispatchQueue.main.async {
                // ‚úÖ Ch·ªâ startRecording n·∫øu app v·∫´n active + c√≤n ·ªü tr·∫°ng th√°i l·∫Øng nghe
                if UIApplication.shared.applicationState == .active, self.isListening {
                    do {
                        try self.startRecording()
                    } catch {
                        self.announce("Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông micro")
                        self.isListening = false
                    }
                } else {
                    print("‚ùå B·ªè qua startRecording v√¨ app kh√¥ng active ho·∫∑c ƒë√£ stop")
                }
            }
        }
    }
    
    func speak(_ text: String, completion: (() -> Void)? = nil) {
        announce(text, completion: completion)
    }
    
    func stopSpeaking() {
        if synthesizer.isSpeaking {
            synthesizer.stopSpeaking(at: .word)
        }
    }
    
    private func announce(_ text: String, completion: (() -> Void)? = nil) {
        DispatchQueue.main.async {
            print("announce: \(text)")
            UIAccessibility.post(notification: .announcement, argument: text)
            
            // üîÑ Reset AudioSession ƒë·ªÉ ch·∫Øc ch·∫Øn c√≥ ti·∫øng
            do {
                let audioSession = AVAudioSession.sharedInstance()
                try audioSession.setActive(false, options: .notifyOthersOnDeactivation)
                try audioSession.setCategory(.playback, mode: .spokenAudio, options: [.duckOthers])
                try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
            } catch {
                print("‚ùå Failed to reset audio session: \(error)")
            }

            // üîÑ N·∫øu ƒëang ƒë·ªçc th√¨ d·ª´ng ngay
            if self.synthesizer.isSpeaking {
                self.synthesizer.stopSpeaking(at: .immediate)
            }

            self.announceCompletion = completion

            // üîπ L·∫•y t·ªëc ƒë·ªô ƒë·ªçc t·ª´ UserDefaults (m·∫∑c ƒë·ªãnh 0.5)
            let savedRate = UserDefaults.standard.float(forKey: StringResources.key_speechRate)
            let rate = (savedRate > 0) ? savedRate : StringResources.default_speak_rate

            // üîπ L·∫•y danh s√°ch gi·ªçng ti·∫øng Vi·ªát
            let voices = AVSpeechSynthesisVoice.speechVoices().filter { $0.language.hasPrefix("vi") }

            // üîπ L·∫•y index gi·ªçng t·ª´ UserDefaults
            let voiceIndex = SettingsViewController.usd_getInt(
                for: StringResources.key_speechVoice,
                default: 0
            )

            // üîπ Ch·ªçn gi·ªçng, n·∫øu index out of range th√¨ fallback gi·ªçng ƒë·∫ßu ti√™n
            let selectedVoice: AVSpeechSynthesisVoice
            if voiceIndex >= 0 && voiceIndex < voices.count {
                selectedVoice = voices[voiceIndex]
            } else {
                selectedVoice = AVSpeechSynthesisVoice(language: "vi-VN")!
            }

            // üîπ T·∫°o utterance
            let utterance = AVSpeechUtterance(string: text)
            utterance.voice = selectedVoice
            utterance.rate = rate

            // üîä ƒê·ªçc
            self.synthesizer.speak(utterance)
        }
    }

    func stopListening() {
        print("stopListening called")

        // Ng·∫Øt timer
        silenceTimer?.invalidate()
        silenceTimer = nil

        // Ng·∫Øt audio engine
        if audioEngine.isRunning {
            audioEngine.stop()
            audioEngine.inputNode.removeTap(onBus: 0)
        }
        request?.endAudio()
        task?.cancel()
        task = nil
        request = nil

        // Reset state
        isListening = false

    }
        
    // D·ª´ng to√†n b·ªô: mic + timer + TTS + reset ƒë·∫øm timeout
    func stopAll(announceStop: Bool = false, resetConver: Bool = true) {
        print("stopAll called")
        
        UIApplication.shared.isIdleTimerDisabled = false

        isManuallyStopped = true  // üî¥ ƒë√°nh d·∫•u l√† d·ª´ng ch·ªß ƒë·ªông

        // d·ª´ng nghe (kh√¥ng announce ·ªü ƒë√¢y ƒë·ªÉ tr√°nh ch·ªìng l·ªùi)
        stopListening()

        // d·ª´ng ƒë·ªçc ngay l·∫≠p t·ª©c
        if synthesizer.isSpeaking {
            synthesizer.stopSpeaking(at: .immediate)
        }
        announceCompletion = nil

        // reset state
        timeoutCount = 0
        isListening = false
        
        if(resetConver){
            resetConversation()
        }
        
        NotificationCenter.default.post(
            name: .micStateChanged,
            object: nil,
            userInfo: ["isListening": false]
        )

        if announceStop {
            announce("ƒê√£ d·ª´ng tr·ª£ l√Ω gi·ªçng n√≥i")
        }
    }

    // Public API ƒë·ªÉ ViewController g·ªçi ƒë·ªçc 1 c√¢u v√† nh·∫≠n completion khi ƒë·ªçc xong

    private func startRecording() throws {
        print("startRecording")

        task?.cancel()
        request = SFSpeechAudioBufferRecognitionRequest()
        request?.shouldReportPartialResults = true

        let audioSession = AVAudioSession.sharedInstance()
        try audioSession.setCategory(.playAndRecord, mode: .measurement,
                                     options: [.duckOthers, .allowBluetooth, .defaultToSpeaker])
        try audioSession.setActive(true, options: .notifyOthersOnDeactivation)

        let inputNode = audioEngine.inputNode
        let format = inputNode.outputFormat(forBus: 0)
        inputNode.removeTap(onBus: 0)
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: format) { buffer, _ in
            self.request?.append(buffer)
        }

        audioEngine.prepare()
        try audioEngine.start()

        // ‚úÖ 10s ch·ªù b·∫Øt ƒë·∫ßu n√≥i (n·∫øu ch∆∞a n√≥i g√¨)
        startSpeakingTimer?.invalidate()
        startSpeakingTimer = Timer.scheduledTimer(withTimeInterval: 10, repeats: false) { [weak self] _ in
            guard let self = self else { return }
            print("Start-speaking timeout 10s: user ch∆∞a n√≥i g√¨")
            if (self.isManuallyStopped) {
                print("nhay vao timeout nhung da goi isManuallyStopped true")
                return
            }
            self.isStoppedByTimeout = true
            // D·ª´ng thu √¢m tr∆∞·ªõc khi th√¥ng b√°o
            self.stopListening()
            // TƒÉng b·ªô ƒë·∫øm timeout chu·ªói
            self.timeoutCount += 1
            
            print("timeoutCount = \(self.timeoutCount)")
            
            if self.timeoutCount >= self.maxTimeoutCount {
                self.announce("B·∫°n ƒë√£ y√™n l·∫∑ng qu√° l√¢u, tr·ª£ l√Ω s·∫Ω d·ª´ng l·∫°i") {
                    self.stopAll(announceStop: false)
                }
            } else {
                print ("startSpeakingTimer timeout")
                self.announce("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c c√¢u h·ªèi") {
                    DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
                        self.startListening(startApp: false)
                    }
                }
            }
        }

        task = recognizer?.recognitionTask(with: request!) { [weak self] result, error in
            guard let self = self else { return }

            if let nsError = error as NSError? {
                if self.isStoppedByTimeout {
                    // ‚ùå B·ªè qua error gi·∫£ khi timeout, ƒë√£ x·ª≠ l√Ω b·∫±ng timer
                    print("finish by timeout (b·ªè qua error) \(nsError.domain) \(nsError.code)")
                    return
                }else if self.isManuallyStopped {
                    print("Recognition stopped manually, b·ªè qua error")
                    return
                }else {
                    // ‚úÖ Th·∫≠t s·ª± l·ªói
                    print("Recognition error: \(nsError.domain) \(nsError.code) - \(nsError.localizedDescription)")
                    self.announce("C√≥ l·ªói khi nh·∫≠n d·∫°ng gi·ªçng n√≥i, vui l√≤ng kh·ªüi ƒë·ªông l·∫°i ·ª©ng d·ª•ng")
                    self.stopAll()
                    return
                }
            }

            guard let result = result else { return }

            let transcript = result.bestTranscription.formattedString
            print("N·ªôi dung n√≥i: \(transcript) | ƒë√£ xong: \(result.isFinal)")

            if !transcript.isEmpty {
                self.lastTranscript = transcript

                // Ng∆∞·ªùi d√πng ƒë√£ b·∫Øt ƒë·∫ßu n√≥i ‚Üí hu·ª∑ timer 10s v√† chuy·ªÉn sang ƒë·∫øm im l·∫∑ng 3s
                if self.startSpeakingTimer != nil {
                    self.startSpeakingTimer?.invalidate()
                    self.startSpeakingTimer = nil
                }
                // ‚úÖ M·ªói l·∫ßn c√≥ partial ‚Üí reset 3s ƒë·ªÉ kh√¥ng c·∫Øt ngang khi ƒëang n√≥i
                self.resetSilenceTimer()
            }

            if result.isFinal {
                print("N·ªôi dung cu·ªëi c√πng: \(transcript)")
                self.stopListening()
                self.handleRecognizedText(transcript)
            }
        }

        // ‚ùå Tr∆∞·ªõc ƒë√¢y g·ªçi resetSilenceTimer() ngay t·∫°i ƒë√¢y ‚Üí g√¢y timeout 3s d√π user ch∆∞a n√≥i.
        // ƒê√É B·ªé ƒë·ªÉ tu√¢n th·ªß: 10s ch·ªù b·∫Øt ƒë·∫ßu n√≥i, sau khi c√≥ ti·∫øng n√≥i m·ªõi ƒë·∫øm 3s im l·∫∑ng.
    }

    private func resetSilenceTimer() {
        silenceTimer?.invalidate()
        silenceTimer = Timer.scheduledTimer(withTimeInterval: 3, repeats: false) { [weak self] _ in
            guard let self = self else { return }
            print("Silence timeout 3s ‚Üí finishRecognitionAfterTimeout")
            self.isStoppedByTimeout = true
            self.finishRecognitionAfterTimeout()
        }
    }

    private func finishRecognitionAfterTimeout() {
        
        maxTimeoutCount = SettingsViewController.usd_getInt(for: StringResources.key_time_out, default: StringResources.default_time_out_count)
        
        if isManuallyStopped { return }
        
        request?.endAudio()
        
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
            if self.isListening {
                self.stopListening()
                
                if let transcript = self.lastTranscript, !transcript.isEmpty {
                    print("Final text (timeout): \(transcript)")
                    self.handleRecognizedText(transcript)
                } else {
                    // tƒÉng s·ªë l·∫ßn timeout
                    self.timeoutCount += 1
                    if self.timeoutCount >= self.maxTimeoutCount {
                        // qu√° nhi·ªÅu l·∫ßn im l·∫∑ng -> stop h·∫≥n
                        self.announce("B·∫°n ƒë√£ im l·∫∑ng qu√° l√¢u, tr·ª£ l√Ω s·∫Ω d·ª´ng l·∫°i") {
                            self.stopAll()
                        }
                    } else {
                        // b√¨nh th∆∞·ªùng -> th√¥ng b√°o v√† quay l·∫°i v√≤ng l·∫∑p
                        self.announce("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c c√¢u h·ªèi") {
                            print ("finishRecognitionAfterTimeout")
                            DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
                                self.startListening(startApp: false)
                            }
                        }
                    }
                }
            }
        }
    }

    private func handleRecognizedText(_ text: String) {
        
        timeoutCount = 0

        let lower = text.lowercased().trimmingCharacters(in: .whitespacesAndNewlines)
        
        if stopCommands.contains(lower) {
            self.announce("ƒê√£ d·ª´ng tr·ª£ l√Ω gi·ªçng n√≥i") {
                self.stopAll()
            }
            return
        }
        
        if cameraCommands.contains(where: { lower.contains($0) }) {
            self.announce("M·ªü t√≠nh nƒÉng nh·∫≠n d·∫°ng") {
                
                self.stopAll()
                
                self.delegate?.didRequestOpenCamera()

            }
            return
        }
        
//        if callCommands.contains(lower) {
//            
//            let phone_number = SettingsViewController.usd_getString(for: StringResources.key_phone_number, default: StringResources.default_phone_number)
//
//            self.announce("T√¥i s·∫Ω m·ªü m√†n h√¨nh cu·ªôc g·ªçi ƒë·∫øn s·ªë \(phone_number), b·∫°n c·∫ßn b·∫•m n√∫t g·ªçi c√°ch ph√≠a d∆∞·ªõi m√†n h√¨nh 2 centimet ƒë·ªÉ g·ªçi v√† ƒë∆∞a ƒëi·ªán tho·∫°i l√™n s√°t tai ƒë·ªÉ giao ti·∫øp.") {
//                
//                self.stopAll()
//                
//                if let phoneURL = URL(string: "tel://\(phone_number)") {
//                    if UIApplication.shared.canOpenURL(phoneURL) {
//                        UIApplication.shared.open(phoneURL, options: [:], completionHandler: nil)
//                    } else {
//                        print("Kh√¥ng th·ªÉ m·ªü URL g·ªçi ƒëi·ªán")
//                    }
//                }
//
//            }
//            return
//        }
        
        if timeCommands.contains(where: { lower.contains($0) }) {
            
            self.stopAll()

            let now = Date()
            let cal = Calendar.current
            let h = cal.component(.hour, from: now)
            let m = cal.component(.minute, from: now)

            let date_string = "B√¢y gi·ªù l√† \(h) gi·ªù \(m) ph√∫t"
            self.announce(date_string) {
                DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
                    self.startListening(startApp: false)
                }
            }
            return
        }
        
        if dateCommands.contains(lower) {
            
            self.stopAll()

            let now = Date()
            let cal = Calendar.current
            let d = cal.component(.day, from: now)
            let mo = cal.component(.month, from: now)
            let y = cal.component(.year, from: now)
            
            let formatter = DateFormatter()
            formatter.locale = Locale(identifier: "vi_VN")
            formatter.dateFormat = "EEEE"   // ho·∫∑c "EEEE, dd/MM/yyyy"

            let weekdayString = formatter.string(from: now)
            
            let date_string = "H√¥m nay l√† \(weekdayString) \(d) th√°ng \(mo) nƒÉm \(y)"
            self.announce(date_string) {
                DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
                    self.startListening(startApp: false)
                }
            }
            return
        }
        
        if lunaCommands.contains(lower) {
            
            self.stopAll()

            self.announce("H√¥m nay l√† " + getLunarDateString() + " √¢m l·ªãch") {
                DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
                    self.startListening(startApp: false)
                }
            }
            return
        }
        
        if guideCommands.contains(lower) {
            self.announce(StringResources.huong_dan_su_dung) {
                self.stopAll(resetConver: false)

                DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
                    self.startListening(startApp: false)
                }
            }
            return
        }
        
        if speedDecraseCommands.contains(lower) {
            
            var result: String = ""

            var speed = SettingsViewController.usd_getFloat(for: StringResources.key_speechRate, default: StringResources.default_speak_rate)
            if (speed - AVSpeechUtteranceMinimumSpeechRate > 0.11){
                speed = speed - 0.1
                UserDefaults.standard.set(speed, forKey: StringResources.key_speechRate)
                print("Speed is \(speed)")
                
                result = "ƒê√£ gi·∫£m t·ªëc ƒë·ªô ƒë·ªçc"

            }else {
                result = "T·ªëc ƒë·ªô ƒë·ªçc ƒë√£ ch·∫≠m nh·∫•t"
            }

            self.announce(result) {
                
                self.stopAll()

                DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
                    self.startListening(startApp: false)
                }
            }
            return
        }
        
        if speedIncreaseCommands.contains(lower) {
            
            var result: String = ""
            
            var speed = SettingsViewController.usd_getFloat(for: StringResources.key_speechRate, default: StringResources.default_speak_rate)
            if (AVSpeechUtteranceMaximumSpeechRate - speed > 0.1){
                speed = speed + 0.1
                UserDefaults.standard.set(speed, forKey: StringResources.key_speechRate)
                print("Speed is \(speed)")
                result = "ƒê√£ tƒÉng t·ªëc ƒë·ªô ƒë·ªçc"
            }else {
                result = "T·ªëc ƒë·ªô ƒë·ªçc ƒë√£ nhanh nh·∫•t"
            }
            
            self.announce(result) {
                
                self.stopAll()

                DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
                    self.startListening(startApp: false)
                }
            }
            return
        }


        // B∆∞·ªõc 1: N√≥i tr∆∞·ªõc "ƒêang t√¨m c√¢u tr·∫£ l·ªùi"
        self.announce("ƒêang t√¨m c√¢u tr·∫£ l·ªùi") {
            
            self.stopAll(resetConver: false)

            let startTime = Date()

            //demo tr√™n ƒëi·ªán tho·∫°i th√¨ g·ªçi tr·ª±c ti·∫øp
//            self.generateQuote(forMood: text) { quote in
//                let elapsed = Date().timeIntervalSince(startTime)
//                let delay = max(0, 2 - elapsed)  // ƒë·∫£m b·∫£o t·ªëi thi·ªÉu 2s
//
//                DispatchQueue.main.asyncAfter(deadline: .now() + delay) {
//                    self.announce(quote ?? "Xin l·ªói, t√¥i ch∆∞a c√≥ c√¢u tr·∫£ l·ªùi") {
//                        // ‚è≥ Sau khi n√≥i xong th√¨ quay l·∫°i v√≤ng l·∫∑p
//                        DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
//                            self.startListening(startApp: false)
//                        }
//                    }
//                }
//            }
            
            //tri·ªÉn hhai th·ª±c t·∫ø g·ªçi backend
            self.askBackend(newQuestion: text) { answer in
                print("Tr·∫£ l·ªùi t·ª´ backend: \(String(describing: answer))")
                let elapsed = Date().timeIntervalSince(startTime)
                let delay = max(0, 2 - elapsed)  // ƒë·∫£m b·∫£o t·ªëi thi·ªÉu 2s

                DispatchQueue.main.asyncAfter(deadline: .now() + delay) {
                    self.announce(answer ?? "Xin l·ªói, t√¥i ch∆∞a c√≥ c√¢u tr·∫£ l·ªùi") {
                        // ‚è≥ Sau khi n√≥i xong th√¨ quay l·∫°i v√≤ng l·∫∑p
                        DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
                            self.startListening(startApp: false)
                        }
                    }
                }
            }
            
        }
    }

//    func generateQuote(forMood newQuestion: String, completion: @escaping (String?) -> Void) {
//        // 1) Th√™m c√¢u h·ªèi m·ªõi c·ªßa user v√†o l·ªãch s·ª≠
//        conversationHistory.append(["role": "user", "content": newQuestion])
//
//        // 2) Gh√©p to√†n b·ªô h·ªôi tho·∫°i th√†nh 1 prompt
//        var fullContext = "Tr·∫£ l·ªùi ng·∫Øn g·ªçn, kh√¥ng qu√° 100 t·ª´. "
//        for msg in conversationHistory {
//            if msg["role"] == "user" {
//                fullContext += "Ng∆∞·ªùi d√πng: \(msg["content"]!)\n"
//            } else if msg["role"] == "assistant" {
//                fullContext += "Tr·ª£ l√Ω: \(msg["content"]!)\n"
//            }
//        }
//        fullContext += "\nTr·ª£ l√Ω:"
//
//        // üëâ GPT-5 d√πng /responses thay v√¨ /chat/completions
//        let endpoint = URL(string: "https://api.openai.com/v1/responses")!
//        var request = URLRequest(url: endpoint)
//        request.httpMethod = "POST"
//        request.addValue("Bearer \(StringResources.GPT_KEY)", forHTTPHeaderField: "Authorization")
//        request.addValue("application/json", forHTTPHeaderField: "Content-Type")
//
//        // Body format cho /responses
//        let body: [String: Any] = [
//            "model": "gpt-5-mini",
//            "input": [
//                ["role": "user", "content": fullContext]
//            ],
////            "max_output_tokens": 300
//        ]
//
//        request.httpBody = try? JSONSerialization.data(withJSONObject: body)
//
//        URLSession.shared.dataTask(with: request) { data, _, _ in
//            guard let data = data else {
//                completion(nil)
//                return
//            }
//
//            guard let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any] else {
//                completion(nil)
//                return
//            }
//
//            // 1) ∆Øu ti√™n field output_text (n·∫øu c√≥)
//            if let outputText = json["output_text"] as? String, !outputText.isEmpty {
//                let text = outputText.trimmingCharacters(in: .whitespacesAndNewlines)
//                self.conversationHistory.append(["role": "assistant", "content": text])
//                completion(text)
//                return
//            }
//
//            // 2) N·∫øu kh√¥ng c√≥, duy·ªát output[].content[].text
//            if let outputs = json["output"] as? [[String: Any]] {
//                for item in outputs {
//                    if let contents = item["content"] as? [[String: Any]] {
//                        for content in contents {
//                            if let text = content["text"] as? String {
//                                let cleaned = text.trimmingCharacters(in: .whitespacesAndNewlines)
//                                self.conversationHistory.append(["role": "assistant", "content": cleaned])
//                                completion(cleaned)
//                                return
//                            }
//                        }
//                    }
//                }
//            }
//
//            // 3) Kh√¥ng parse ƒë∆∞·ª£c ‚Üí tr·∫£ nil
//            completion(nil)
//        }.resume()
//    }

    func askBackend(newQuestion: String, completion: @escaping (String?) -> Void) {
        
//        guard NetworkMonitor.shared.isConnected else {
//            print("‚ùå Kh√¥ng c√≥ k·∫øt n·ªëi internet")
//            completion("Kh√¥ng c√≥ k·∫øt n·ªëi internet. Vui l√≤ng ki·ªÉm tra l·∫°i.")
//            return
//        }
        
        // 1) Th√™m c√¢u h·ªèi m·ªõi c·ªßa user v√†o l·ªãch s·ª≠
        conversationHistory.append(["role": "user", "content": newQuestion])

        // 2) Gh√©p to√†n b·ªô h·ªôi tho·∫°i th√†nh 1 prompt
//        var fullContext = "H√£y nh·ªõ ng·ªØ c·∫£nh tr∆∞·ªõc ƒë√≥ ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c. Lu√¥n tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch, kh√¥ng qu√° 50 t·ª´."
        var fullContext = "Tr·∫£ l·ªùi ng·∫Øn g·ªçn, kh√¥ng qu√° 100 t·ª´. "

        for msg in conversationHistory {
            if msg["role"] == "user" {
                fullContext += "Ng∆∞·ªùi d√πng: \(msg["content"]!)\n"
            } else if msg["role"] == "assistant" {
                fullContext += "Tr·ª£ l√Ω: \(msg["content"]!)\n"
            }
        }
        fullContext += "\nTr·ª£ l√Ω:"
        
        print("to√†n b·ªô n·ªôi dung g·ª≠i t·ªõi backend: \(fullContext)")

        // 3) G·ª≠i request t·ªõi backend
        guard let url = URL(string: StringResources.url_gpt_new) else {
            print("‚ùå URL kh√¥ng h·ª£p l·ªá")
            completion(nil)
            return
        }

        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.addValue("application/json", forHTTPHeaderField: "Content-Type")

        let body: [String: Any] = ["question": fullContext]
        request.httpBody = try? JSONSerialization.data(withJSONObject: body)

        // 4) G·ªçi API
        URLSession.shared.dataTask(with: request) { data, response, error in
            if let error = error {
                print("‚ùå L·ªói g·ªçi backend:", error)
                completion(nil)
                return
            }

            guard let data = data else {
                print("‚ùå Kh√¥ng nh·∫≠n ƒë∆∞·ª£c d·ªØ li·ªáu t·ª´ backend")
                completion(nil)
                return
            }

            do {
                if let json = try JSONSerialization.jsonObject(with: data) as? [String: Any] {
                    print("‚úÖ JSON tr·∫£ v·ªÅ:", json)

                    // ‚ö° Check remaining
                    if let remaining = json["remaining"] as? Int, remaining == 0 {
                        let message = "B·∫°n ƒë√£ d√πng h·∫øt l∆∞·ª£t c√¢u h·ªèi √¢y ai ng√†y h√¥m nay"
                        completion(message)
                        return
                    }

                    if let answer = json["answer"] as? String {
                        // 5) L∆∞u c√¢u tr·∫£ l·ªùi v√†o l·ªãch s·ª≠
                        self.conversationHistory.append(["role": "assistant", "content": answer])
                        completion(answer)
                    } else {
                        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y field 'answer'")
                        completion(nil)
                    }
                } else {
                    print("‚ùå Kh√¥ng parse ƒë∆∞·ª£c JSON t·ª´ backend")
                    completion(nil)
                }
            } catch {
                print("‚ùå L·ªói parse JSON:", error)
                completion(nil)
            }
        }.resume()
    }
    
    func getLunarDateString(from date: Date = Date()) -> String {
        // L·∫•y th·ª© d∆∞∆°ng
        let solarFormatter = DateFormatter()
        solarFormatter.locale = Locale(identifier: "vi_VN")
        solarFormatter.dateFormat = "EEEE"  // v√≠ d·ª•: "Th·ª© NƒÉm"
        let weekday = solarFormatter.string(from: date)

        // L·∫•y ng√†y √¢m
        let chineseCalendar = Calendar(identifier: .chinese)
        let comps = chineseCalendar.dateComponents([.day, .month, .year], from: date)

        if let day = comps.day, let month = comps.month, let year = comps.year {
            return "ng√†y \(day) th√°ng \(month)"
        }
        return ""
    }

    weak var delegate: VoiceManagerDelegate?

}
protocol VoiceManagerDelegate: AnyObject {
    func didRequestOpenCamera()
}
